{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum-Inspired Acromyrmex Evolutionary Algorithm (QIAEA) in Graph Clustering\n",
    "\n",
    "The notebook contains first experimental algorithm implementation for graph clustering problem via QIAEA.\n",
    "\n",
    "The graph for algorithm is built on the dataset \"Relato Business Graph Database\", that can be downloaded by <a href=\"https://www.kaggle.com/datasets/thedevastator/relato-business-network-graph-373663-domain-conn\">link</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Download and Clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fatkh\\AppData\\Local\\Temp\\ipykernel_16500\\2811395870.py:1: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  links = pd.read_csv(\"dataset/links.csv\")\n"
     ]
    }
   ],
   "source": [
    "links = pd.read_csv(\"dataset/links.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 112675 entries, 0 to 360547\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   home_name  112675 non-null  object\n",
      " 1   link_name  112675 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.6+ MB\n"
     ]
    }
   ],
   "source": [
    "links = links.drop(['index', '_id', 'update_time', 'home_domain', 'link_domain', 'username', 'name'], axis=1)\n",
    "links = links.dropna()\n",
    "links = links[links['type'] == 'partnership'].drop(['type'], axis=1)\n",
    "links = links.drop_duplicates()\n",
    "links.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43065"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies = np.unique_values(\n",
    "    np.concatenate(\n",
    "        (links['home_name'].unique(), links['link_name'].unique())\n",
    "        ).astype('str')\n",
    "    )\n",
    "companies = np.sort(companies)\n",
    "len(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_companies = dict()\n",
    "for idx, company in enumerate(companies):\n",
    "    map_companies[company] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112675"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = []\n",
    "for link in links.values:\n",
    "    edges.append([map_companies[link[0]], map_companies[link[1]]])\n",
    "    \n",
    "edges = np.array(edges)\n",
    "len(edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Declarations\n",
    "\n",
    "- **Graph** - object that contain all the information about the graph: vertices, edges, degrees of vertices, modularity calculation;\n",
    "- **Partition** - object that represents clusterization of a graph. The Partition consists of quantum and collapsed (determined) chromosomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    def __init__(self, vertices: np.ndarray, edges: np.ndarray):\n",
    "        self.number_of_vertices = len(vertices)\n",
    "        self.number_of_edges = len(edges)\n",
    "        self.vertices = vertices\n",
    "        self.edges = edges\n",
    "        assert edges.shape[1] == 2\n",
    "        self.degrees = np.zeros((self.number_of_vertices,))\n",
    "\n",
    "        for edge in edges:\n",
    "            self.degrees[edge[0]] += 1\n",
    "            self.degrees[edge[1]] += 1\n",
    "\n",
    "    def modularity(self, labels: np.ndarray, k_max: int):\n",
    "        degree_per_cluster = np.bincount(labels, self.degrees, minlength=k_max)\n",
    "\n",
    "        from_clusters = labels[edges[:, 0]]\n",
    "        to_clusters = labels[edges[:, 1]]\n",
    "\n",
    "        mask = (from_clusters == to_clusters)\n",
    "\n",
    "        edges_per_cluster = np.bincount(from_clusters[mask], minlength=k_max).astype('int32')\n",
    "\n",
    "        modularity = np.sum(edges_per_cluster / self.number_of_edges) - np.sum((degree_per_cluster / (2 * self.number_of_edges)) ** 2)\n",
    "\n",
    "        return modularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Partition:\n",
    "    def __init__(self, number_of_vertices: np.ndarray, k_max: int):\n",
    "        assert k_max < 256\n",
    "        self.number_of_vertices = number_of_vertices\n",
    "        self.k_max = k_max\n",
    "        self.fitness = -0.5\n",
    "        self.gene_len = 1\n",
    "\n",
    "        while 2**(self.gene_len) < k_max:\n",
    "            self.gene_len += 1\n",
    "\n",
    "        self.chromosome = np.random.rand(number_of_vertices, self.gene_len, 2)\n",
    "        self.chromosome[:, :, 1] = np.sqrt(1 - self.chromosome[:, :, 0]**2)\n",
    "        self.collapsed_chromosome = None\n",
    "\n",
    "    def __copy__(self):\n",
    "        obj = Partition(self.number_of_vertices, self.k_max)\n",
    "        obj.fitness = self.fitness\n",
    "        obj.gene_len = self.gene_len\n",
    "        obj.chromosome = np.copy(self.chromosome)\n",
    "        obj.collapsed_chromosome = np.copy(self.collapsed_chromosome)\n",
    "        return obj\n",
    "\n",
    "    def collapse(self):\n",
    "        labels = np.zeros((self.number_of_vertices,), dtype='int32')\n",
    "        measure = np.random.rand(self.chromosome.shape[0], self.chromosome.shape[1])\n",
    "        measured_chromosome = self.chromosome[:, :, 1] > measure\n",
    "        labels = np.packbits(measured_chromosome, axis=1, bitorder='little').flatten()\n",
    "        labels = labels % self.k_max\n",
    "        self.collapsed_chromosome = labels\n",
    "\n",
    "    def calculate_fitness(self, graph: Graph):\n",
    "        self.fitness = graph.modularity(self.collapsed_chromosome, self.k_max)\n",
    "        self.fitness = (self.fitness + 0.5) * 2 / 3\n",
    "\n",
    "    def mutation(self, number_of_mutations: int = 1):\n",
    "        assert number_of_mutations >= 1\n",
    "\n",
    "        new_partition = Partition(self.number_of_vertices, self.k_max)\n",
    "        new_partition.chromosome = np.copy(self.chromosome)\n",
    "\n",
    "        for _ in range(number_of_mutations):\n",
    "            gene, location = np.random.randint(0, self.number_of_vertices), np.random.randint(0, self.gene_len)\n",
    "            alpha, beta = new_partition.chromosome[gene][location][0], new_partition.chromosome[gene][location][1]\n",
    "            new_partition.chromosome[gene][location][0], new_partition.chromosome[gene][location][1] = beta, alpha\n",
    "\n",
    "        return new_partition\n",
    "\n",
    "\n",
    "def crossover(partition1: Partition, partition2: Partition) -> Partition:\n",
    "    child = Partition(partition1.number_of_vertices, partition1.k_max)\n",
    "\n",
    "    adamart_operator = np.array([\n",
    "        [1, 1],\n",
    "        [1, -1]\n",
    "    ]) / np.sqrt(2)\n",
    "\n",
    "    xgate_operator = np.array([\n",
    "        [0, 1],\n",
    "        [1, 0]\n",
    "    ])\n",
    "\n",
    "    mask_adamart = (partition1.collapsed_chromosome == partition2.collapsed_chromosome)\n",
    "    mask_xgate = (partition1.collapsed_chromosome != partition2.collapsed_chromosome)\n",
    "    child.chromosome[mask_adamart] = child.chromosome[mask_adamart] @ adamart_operator.T\n",
    "    child.chromosome[mask_xgate] = child.chromosome[mask_xgate] @ xgate_operator.T\n",
    "    return child\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Implementation\n",
    "The QIAEA is applied for graph clusterization problem to a specific dataset.\n",
    "\n",
    "Key details:\n",
    "- Each vertex in partitions has length B, where <math>$$2^{B-1} < \\#\\_of\\_clusters < 2^B$$</math>\n",
    "- In case number of clusters less than 2**B, the first clusters are defined by two numbers\n",
    "- Crossover operation is fully implemented as described in the <a href=\"https://www.nature.com/articles/s41598-019-48409-5\">paper</a>\n",
    "- Mutation operation replace alpha and beta of random allels, number of mutations is a parameter.\n",
    "- Measurement operation is fully implemented as descrived in the <a href=\"https://www.nature.com/articles/s41598-019-48409-5\">paper</a>. This operation is necessary for calculating fitnees, as soon as fitness is defined only on determined state of an organism\n",
    "- Modularity is used as a graph clusterization metric. Modularity is in the range [-0.5, 1].\n",
    "- Fitness value is based on the modularity and is calculated by the formula: <math>$$fitness = {{2 * (modularity + 0.5)}\\over{3}}$$</math>, so the fitness value is in range [0, 1]\n",
    "\n",
    "Notice that most of the graphs do not have clustering with high modularity. The high modularity cannot be achieved in such graphs due to its structure, where there are no actual groups of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_size = 500\n",
    "number_of_males = population_size // 2\n",
    "max_number_of_clusters = 32\n",
    "number_of_epochs = 15\n",
    "graph = Graph(companies, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = [Partition(len(companies), max_number_of_clusters) for _ in range(population_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Epoch 1, best fitness: 0.3339381308504367\n",
      "----------------------------------\n",
      "Epoch 2, best fitness: 0.33401971277346565\n",
      "----------------------------------\n",
      "Epoch 3, best fitness: 0.33401971277346565\n",
      "----------------------------------\n",
      "Epoch 4, best fitness: 0.33437183333071596\n",
      "----------------------------------\n",
      "Epoch 5, best fitness: 0.33437183333071596\n",
      "----------------------------------\n",
      "Epoch 6, best fitness: 0.33437183333071596\n",
      "----------------------------------\n",
      "Epoch 7, best fitness: 0.33437183333071596\n",
      "----------------------------------\n",
      "Epoch 8, best fitness: 0.3347936620642229\n",
      "----------------------------------\n",
      "Epoch 9, best fitness: 0.3347936620642229\n",
      "----------------------------------\n",
      "Epoch 10, best fitness: 0.3347936620642229\n",
      "----------------------------------\n",
      "Epoch 11, best fitness: 0.3347936620642229\n",
      "----------------------------------\n",
      "Epoch 12, best fitness: 0.3347936620642229\n",
      "----------------------------------\n",
      "Epoch 13, best fitness: 0.3347936620642229\n",
      "----------------------------------\n",
      "Epoch 14, best fitness: 0.3347936620642229\n",
      "----------------------------------\n",
      "Epoch 15, best fitness: 0.3347936620642229\n"
     ]
    }
   ],
   "source": [
    "best_partition = population[0].__copy__()\n",
    "for partition in population:\n",
    "    partition.collapse()\n",
    "    partition.calculate_fitness(graph)\n",
    "population.sort(key=lambda x: -x.fitness)\n",
    "\n",
    "for epoch in range(1, number_of_epochs+1):\n",
    "    print(\"----------------------------------\")\n",
    "    # Crossover operations\n",
    "    for i in range(1, number_of_males+1):\n",
    "        population.append(crossover(population[0], population[i]))\n",
    "    # Mutation operations\n",
    "    for i in range(1, population_size):\n",
    "        population.append(population[i].mutation())\n",
    "    # Measure operations\n",
    "    for i in range(population_size, len(population)):\n",
    "        population[i].collapse()\n",
    "    # Fitness calculation\n",
    "    for i in range(population_size, len(population)):\n",
    "        population[i].calculate_fitness(graph)\n",
    "    population.sort(key=lambda x: -x.fitness)\n",
    "\n",
    "    population = population[:population_size]\n",
    "\n",
    "    if population[0].fitness > best_partition.fitness:\n",
    "        best_partition = population[0].__copy__()\n",
    "\n",
    "    print(f\"Epoch {epoch}, best fitness: {best_partition.fitness}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best partition clustering:\n",
      "Number of vertices of cluster 1: 26\n",
      "Number of vertices of cluster 2: 55\n",
      "Number of vertices of cluster 3: 85\n",
      "Number of vertices of cluster 4: 249\n",
      "Number of vertices of cluster 5: 82\n",
      "Number of vertices of cluster 6: 266\n",
      "Number of vertices of cluster 7: 253\n",
      "Number of vertices of cluster 8: 943\n",
      "Number of vertices of cluster 9: 77\n",
      "Number of vertices of cluster 10: 266\n",
      "Number of vertices of cluster 11: 262\n",
      "Number of vertices of cluster 12: 949\n",
      "Number of vertices of cluster 13: 277\n",
      "Number of vertices of cluster 14: 1007\n",
      "Number of vertices of cluster 15: 978\n",
      "Number of vertices of cluster 16: 3449\n",
      "Number of vertices of cluster 17: 70\n",
      "Number of vertices of cluster 18: 300\n",
      "Number of vertices of cluster 19: 259\n",
      "Number of vertices of cluster 20: 964\n",
      "Number of vertices of cluster 21: 265\n",
      "Number of vertices of cluster 22: 971\n",
      "Number of vertices of cluster 23: 948\n",
      "Number of vertices of cluster 24: 3435\n",
      "Number of vertices of cluster 25: 272\n",
      "Number of vertices of cluster 26: 960\n",
      "Number of vertices of cluster 27: 988\n",
      "Number of vertices of cluster 28: 3573\n",
      "Number of vertices of cluster 29: 924\n",
      "Number of vertices of cluster 30: 3486\n",
      "Number of vertices of cluster 31: 3491\n",
      "Number of vertices of cluster 32: 12935\n"
     ]
    }
   ],
   "source": [
    "clusters = [[] for _ in range(max_number_of_clusters)]\n",
    "\n",
    "for vertex, cluster in enumerate(best_partition.collapsed_chromosome):\n",
    "    clusters[cluster].append(companies[vertex])\n",
    "\n",
    "print(\"Best partition clustering:\")\n",
    "for idx, cluster in enumerate(clusters, 1):\n",
    "    print(f\"Number of vertices of cluster {idx}: {len(cluster)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
